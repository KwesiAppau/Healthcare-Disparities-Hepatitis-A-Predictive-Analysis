{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library that is used to manipulate dataframes with the alias pd\n",
    "\n",
    "\n",
    "# Load the library that is used to manipulate arrays with the alias np\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset and store it in the variable dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataset\n",
    "\n",
    "\n",
    "\n",
    "# Print  the summary description of the dataset\n",
    "\n",
    "\n",
    "\n",
    "# Print the first 10 lines of the dataset  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing the functions groupby and size, \\ndetermine how many patients have been  \\ndiagnosed with Hepatitis C and how many are control cases.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using the functions groupby and size, \n",
    "determine how many patients have been  \n",
    "diagnosed with Hepatitis C and how many are control cases.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyplot fuction from the matplotlib library \n",
    "\n",
    "\n",
    "\n",
    "# Plot the histogram of the data using the hist function\n",
    "\n",
    "\n",
    "\n",
    "# Display the plot using the show function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix of the data\n",
    "\n",
    "column=dataset.columns\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(dataset.corr('pearson'), vmin=-1, vmax=1, interpolation='none')\n",
    "ax.set_xticks(np.arange(len(column)))\n",
    "ax.set_yticks(np.arange(len(column)))\n",
    "ax.set_xticklabels(column)\n",
    "ax.set_yticklabels(column)\n",
    "fig.colorbar(cax)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Using the values function, convert the dataset into an array and store it into a variable\n",
    "\n",
    "\n",
    "# Separate the target variable from the rest of the array using positional  indexing\n",
    "\n",
    "\n",
    "# Import the train_test_split from  sklearn.model_selection\n",
    "\n",
    "\n",
    "# Using the function train_test_split split-out 20% validation and 80% training dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the  LogisticRegression function from sklearn.linear_model\n",
    "\n",
    "\n",
    "# Import the DecisionTreeClassifier function from sklearn.tree\n",
    "\n",
    "\n",
    "# Import the KNeighborsClassifier function from sklearn.neighbors\n",
    "\n",
    "\n",
    "# Import the LinearDiscriminantAnalysis function from sklearn.discriminant_analysis\n",
    "\n",
    "\n",
    "# Import the GaussianNB function from sklearn.naive_bayes\n",
    "\n",
    "\n",
    "# Import the SVC function from sklearn.svm \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list called model\n",
    "\n",
    "\n",
    "# Using the append function, add an alias for the model and the  function to the list, \n",
    "# using \"liblinear\" as the solver.\n",
    "# This one has been done for you.\n",
    "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "\n",
    "\n",
    "# Using the append function, add an alias for the Linear Discriminant Analysis model and the \n",
    "# LinearDiscriminantAnalysis function to the list.\n",
    "\n",
    "\n",
    "# Using the append function, add an alias for the K Neighbors Classifier model and the \n",
    "# KNeighborsClassifier function to the list.\n",
    "\n",
    "\n",
    "# Using the append function, add an alias for the Decision Tree Classifier model and the \n",
    "# DecisionTreeClassifier function to the list.\n",
    "\n",
    "\n",
    "# Using the append function, add an alias for the Gaussian Naive Bayes model and the \n",
    "# GaussianNB function to the list.\n",
    "\n",
    "\n",
    "# Using the append function, add an alias for the Support Vector Classifier model and the \n",
    "# SVC function to the list,using 'auto' as the value for the gamma parameter.\n",
    "\n",
    "\n",
    "# Create an empty list called results\n",
    "\n",
    "\n",
    "# Create an empty list called names\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you will create a for loop to test the different models\n",
    "# Import cross_val_score from sklearn.model_selection\n",
    "\n",
    "\n",
    "# Create a for loop that iterates over two variables called name and model\n",
    "\n",
    "\n",
    "# Create an instance of cross_val_score with the following parameters:\n",
    "# model, X_train, Y_train, cv=10, scoring=\"accuracy\" and store the resutls as\n",
    "# a variable called cv_results\n",
    "\n",
    "\n",
    "# Append cv_results  to the previously created empty list called results \n",
    "\n",
    "\n",
    "# Append name to the previously created empty list called names\n",
    "\n",
    "\n",
    "# print the name and the mean of cv_results using the fuction mean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data standarization \n",
    "#### In this section you will reuse the varibles that were previewsly created but the data will be scaled \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler from sklearn.preprocessing \n",
    "\n",
    "\n",
    "# Create an instance of  StandardScaler and store it into a variable called scaler\n",
    "\n",
    "\n",
    "# Fit the training data to the scaler by employing the fit function \n",
    "\n",
    "\n",
    "# Transform the training data to the scaler by employing the transform function and store it into a variable called\n",
    "# X_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you will create a for loop to test the different models with the scaled data\n",
    "# Create an empty list called results\n",
    "\n",
    "\n",
    "# Create an empty list called names\n",
    "\n",
    "# Create a for loop that iterates over two variables called name and model\n",
    "\n",
    "\n",
    "# Create an instance of cross_val_score with the following parameters:\n",
    "# model, X_scaled, Y_train, cv=10, scoring=\"accuracy\" and store the resutls as\n",
    "# a variable called cv_results\n",
    "\n",
    "\n",
    "# Append cv_results  to the previously created empty list called results \n",
    "\n",
    "\n",
    "# Append name to the previously created empty list called names\n",
    "\n",
    "\n",
    "# print the name and the mean of cv_results using the fuction mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tunning\n",
    "\n",
    "#### For this part, take a look a the results of the models and determine which group of models performed better, the scaled or regular. Out of the best group  select the two best performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the best performing group of models were the scaled models, scale the validation data\n",
    "# If not, leave this space blank\n",
    "\n",
    "# Create an instance of the Best performing model and store it into the variabe model\n",
    "\n",
    "\n",
    "# Create a grid of parameters to test for the Best performing model\n",
    "# In the jupyter for the Project example (check the PDF in this folder or the video for Topic 2) there are parameters available for each of the models\n",
    "\n",
    "\n",
    "# Import KFold from sklearn.model_selection \n",
    "\n",
    "\n",
    "# Create an instance of Kfold with the following parameters: n_splits=5, random_state=123, shuffle=True\n",
    "# Store it into a variable called kfold\n",
    "\n",
    "# Import GridSearchCV from sklearn.model_selection \n",
    "\n",
    "\n",
    "# Create an instance of GridSearchCV with the following parameters: estimator=model, param_grid=param_grid, \n",
    "# scoring=\"accuracy\", cv=kfold. Store it into a variable called grid\n",
    "\n",
    "\n",
    "# Fit the validation data to the grid by employing the fit function, store it into a variable called grid_result \n",
    "\n",
    "\n",
    "# The following code will print the results of the grid search\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Best performing model and store it into the variabe model\n",
    "\n",
    "\n",
    "# Create a grid of parameters to test for the Second Best performing model\n",
    "# In the jupyter for the Project example (check the PDF in this folder or the video for Topic 2) there are parameters available for each of the models\n",
    "\n",
    "\n",
    "# Create an instance of Kfold with the following parameters: n_splits=5, random_state=123, shuffle=True\n",
    "# Store it into a variable called kfold\n",
    "\n",
    "\n",
    "# Create an instance of GridSearchCV with the following parameters: estimator=model, param_grid=param_grid, \n",
    "# scoring=\"accuracy\", cv=kfold. Store it into a variable called grid\n",
    "\n",
    "\n",
    "# Fit the validation data to the grid by employing the fit function, store it into a variable called grid_result \n",
    "\n",
    "\n",
    "# The following code will print the results of the grid search\n",
    "\n",
    "# The following code will print out the results of the grid search\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the best performing models after modeling was the scaled, scale the validation data\n",
    "# If not, leave this space blank\n",
    "\n",
    "\n",
    "# Create an instance of the best performing model and store it into the variabe model\n",
    "\n",
    "\n",
    "# Fit the validation data to the model by employing the fit function\n",
    "\n",
    "\n",
    "# Estimate accuracy on validation dataset by employing the transform function on model\n",
    "# store it into a variable called predictions\n",
    "\n",
    "\n",
    "# Import accuracy_score from sklearn.metrics \n",
    "\n",
    "\n",
    "# Import confusion_matrix from sklearn.metrics \n",
    "\n",
    "\n",
    "# Import classification_report from sklearn.metrics \n",
    "\n",
    "\n",
    "# Inside a print statement, call the fuction accuracy_score, with the following parameters:\n",
    "# Y_validation, predictions\n",
    "\n",
    "\n",
    "# Inside a print statement, call the fuction confusion_matrix, with the following parameters:\n",
    "# Y_validation, predictions\n",
    "\n",
    "\n",
    "# Inside a print statement, call the fuction classification_report, with the following parameters:\n",
    "# Y_validation, predictions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
